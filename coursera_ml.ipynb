{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 1\n",
    "===\n",
    "Introduction\n",
    "---\n",
    "\n",
    "* notation: \n",
    "    * $m$: number of training examples\n",
    "    * $x, y$: input (feature) and output (target)\n",
    "    * $(x^{(i)}, y^{(i)})$: the $i$th training example\n",
    "    \n",
    "矽谷都用高階語言寫 ML prototype 再 migrate 到 c++ 等\n",
    "\n",
    "Definition\n",
    "---\n",
    "\n",
    "A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$. \n",
    "\n",
    "\n",
    "Types\n",
    "---\n",
    "* supervised\n",
    "    * regression -- example: given picture, predict age\n",
    "    * classification \n",
    "        * SVM can deal with infinitely many features!\n",
    "* unsupervised (cluster), examples:\n",
    "    * organize computing clusters to make grid computing more productive\n",
    "    * social network\n",
    "    * market segmentation\n",
    "    * cocktail party problem: separate 2 speakers' sound; separate music with speaking\n",
    "    * dataset of patients suffering from heart disease. learn possible clusters to tailor the treatments\n",
    "\n",
    "\n",
    "Hypothesis and Cost Functions\n",
    "---\n",
    "$$\n",
    "h_{\\vec \\theta}(y) = \\theta_0 + \\theta_1 x, \\qquad J(\\vec \\theta) = \\frac{1}{2m}\\sum_{i=1}^m\\left(h_{\\vec \\theta}(x^{(i)}) - y^{(i)}\\right)^2\n",
    "$$\n",
    "\n",
    "Gradient Descent\n",
    "---\n",
    "update $\\theta_0$ and $\\theta_1$ simultaneously: \n",
    "$$\n",
    "\\vec\\theta \\leftarrow \\vec\\theta - \\alpha\\frac{\\partial}{\\partial \\vec\\theta}J(\\vec\\theta) \n",
    "$$\n",
    "\n",
    "learning rate $\\alpha$:  \n",
    "* too small: slow convergence\n",
    "* too large: will diverge\n",
    "\n",
    "Batch Gradient Descent: each step uses all the training examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 2\n",
    "===\n",
    "\n",
    "Feature Scaling \n",
    "---\n",
    "\n",
    "* make sure features are on a similar scale: the convergence will be much faster (ziczac convergence path v.s. straight)\n",
    "* get every feature into [-1, 1] approximately; [0, 3] or [-2, 0.5] are ok, but [-100, 100] is not\n",
    "* scaling and mean normaliztion (do not apply to constant term $x_0 = 1$)\n",
    "\n",
    "$$\n",
    "    \\frac{x_i - \\mu_i}{\\sigma_i}\n",
    "$$\n",
    "\n",
    "* depending on the data set, sometimes divide by range (max - min), not sd\n",
    "\n",
    "Learning Rate\n",
    "---\n",
    "\n",
    "* debugging: to check if the learning is converging, plot the $J(\\theta)$ against number of iterations; it should decrease abter every iteration\n",
    "* for different applications, number of iterations before convergence can be very different\n",
    "* automatic convergence test: declare convergence if $J(\\theta)$ decreases by less than $10^{-3}$ in one iteration\n",
    "    * hard to determine the TOL, so always plot\n",
    "* if $J(\\theta)$ is increasing, or if it's going up and down, most likely the learning rate is too big; use small $\\alpha$\n",
    "* plot the convergence for $\\alpha = 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 0.1, \\ldots$\n",
    "\n",
    "Features and Polynomial\n",
    "---\n",
    "\n",
    "* create new features like $x_1^2, x_1^3, \\sqrt{x_1}, \\ldots$\n",
    "    * feature scaling become important!\n",
    "    * there are feature selection algorithms that choose for you\n",
    "    \n",
    "Normal Equation\n",
    "---\n",
    "\n",
    "* $X$: \"design matrix\" with size (# data points) $\\times$ (# features). \n",
    "* closed form solution: $\\theta = (X^T X)^{-1}X^T y$\n",
    "* no need for feature scaling, no need to choose $\\alpha$, but take $O(n^3)$. \n",
    "* can be slower than iterative algorithm when $n > 10^4$\n",
    "* Octave: ```pint(X'*X)*X'*y```, pinv is pseudo inverse\n",
    "* when is $X^TX$ non-invertible?\n",
    "    * linear dependent (redundant) features, like size in sqft and size in $m^2$\n",
    "    * too many features ($m\\leq n$)\n",
    "* solution to both cases: delete features, or use regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3\n",
    "===\n",
    "\n",
    "Logistic Regression\n",
    "---\n",
    "\n",
    "* classification problem\n",
    "    * 1 is positive set\n",
    "    * 0 is negative set, absence of something\n",
    "* linear regression is too sensitive to outlier to be used as a classification algorithm\n",
    "* logistic regression:\n",
    "\n",
    "\n",
    "$$\n",
    "    h_{\\theta}(x) = g(\\theta^T x) = \\frac{1}{1+e^{-\\theta^T x}} = P(y=1~|~x; \\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "* $x$ is feature, like tumor size\n",
    "\n",
    "Decision Boundary\n",
    "---\n",
    "\n",
    "* $h=0.5$ iff $\\theta^T x = 0$; it's a property of hypothesis, not data set\n",
    "    * if use linear function of features, can only get linear decision boundary\n",
    "    * To get different shape, use polynomial like $x_1^2, x_1x_2, x_2^2, \\ldots$\n",
    "\n",
    "\n",
    "Cost Function\n",
    "---\n",
    "\n",
    "* cost function of logistic regression: cannot use least square; the sigmoid function will make the cost function not convex. Instead, use\n",
    "\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m}\\sum_{i=1}^m \\text{Cost}(h_{\\theta}(x^{(i)}), y^{(i)})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Cost}(h_{\\theta}(x^{(i)}), y^{(i)})=\\begin{cases}\n",
    "        -\\log(h_{\\theta}(x))&\\mbox{ if }y=1\\\\\n",
    "        -\\log(1 - h_{\\theta}(x))&\\mbox{ if }y=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "* There are studies on convexity analysis\n",
    "* Has property that Cost$\\rightarrow\\infty$ whenever get wrong prediction\n",
    "* Simplified cost function: Plug into $J(\\theta)$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Cost}(h_{\\theta}(x^{(i)}), y^{(i)}) = -y\\log(h_{\\theta}(x)) - (1-y)\\log(1-h_{\\theta}(x)) \n",
    "$$\n",
    "\n",
    "\n",
    "* can be derived from MLE\n",
    "* vectorized: \n",
    "\n",
    "\n",
    "$$\n",
    "h=g(X\\theta), \\qquad J(\\theta)=\\frac1m(-y^T\\log(h) - (1-y)^T\\log(1-h))\n",
    "$$\n",
    "\n",
    "\n",
    "* Gradient descent: same $\\frac{\\partial }{\\partial \\theta_j}J(\\theta)$ formula as linear regression, only $h_\\theta$ has different definition\n",
    "* vectorized: \n",
    "\n",
    "\n",
    "$$\n",
    "\\theta \\leftarrow \\theta - \\frac{\\alpha}{m}X^T(g(X\\theta) - \\vec y)\n",
    "$$\n",
    "\n",
    "\n",
    "* Feature scaling can also speed up the optimization in logistic regression\n",
    "\n",
    "\n",
    "\n",
    "Implementation\n",
    "---\n",
    "\n",
    "* Optimization algorithm\n",
    "    * Gradient descent \n",
    "    * CG\n",
    "    * BFGS\n",
    "        * use an inner loop, the line search algorithm, to pick learning rate automatically \n",
    "    * L-BFGS\n",
    "\n",
    "* Function minimization unconstrained in Octave for\n",
    "    * @costFunction is function pointer\n",
    "    * options is a data structure for configuration. 'GraObj' and 'on' means the derivative is provided \n",
    "    * initialTheta is the initial guess\n",
    "    * at least in 2 dimensions\n",
    "    * help fminunc to read the doc\n",
    "$$\n",
    "    J(\\theta) = (\\theta_1 - 5)^2 + (\\theta_2 - 5)^2:\n",
    "$$\n",
    "\n",
    "```\n",
    "function [jVal, gradient] = costFunction(theta)\n",
    "\n",
    "    jVal = (theta(1)-5)^2 + (theta(1)-5)^2;\n",
    "    gradient = zeros(2, 1); \n",
    "    gradient(1) = 2*(theta(1)-5);\n",
    "    gradient(2) = 2*(theta(2)-5);\n",
    "    \n",
    "options = optimset('GradObj', 'on', 'MaxIter', '100');\n",
    "initialTheta = zeros(2, 1);\n",
    "[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); \n",
    "```\n",
    "\n",
    "Multi-Class\n",
    "---\n",
    "\n",
    "* email folder: work, friends, family, hobby...\n",
    "* one vs all algorithm\n",
    "* for all $i$, predict $P(~y\\in \\text{class}~i~|~x; \\theta~)$; choose $y\\in \\text{class }(\\text{argmax } P)$\n",
    "\n",
    "Overfitting and Regularization\n",
    "---\n",
    "\n",
    "* too many features, hypothesis fits the training set very well (almost zero cost) but fail to generalize to new examples\n",
    "* 3 types of fitting result: \n",
    "    * underfit (high bias)\n",
    "    * just right\n",
    "    * overfit (high variance)\n",
    "* solution: \n",
    "    * reduce number of features\n",
    "        * manually select which features\n",
    "        * feature selection algorithms\n",
    "    * regularization: work well for many slightly useful features\n",
    "\n",
    "\n",
    "$$\n",
    "J(\\vec \\theta) = \\frac{1}{2m}\\left[\\sum_{i=1}^m\\left(h_{\\vec \\theta}(x^{(i)}) - y^{(i)} \\right)^2 + \\lambda \\sum_{i=1}^n \\theta_i^2\\right]\n",
    "$$\n",
    "    \n",
    "\n",
    "* 1st term: keep good fit\n",
    "* 2nd term: keep hypothesis simple\n",
    "* $\\lambda$: regularization parameter, control balance\n",
    "* convention is not to penalize $\\theta_0$ term: index starts from 1. For large $\\lambda$, $h\\approx \\theta_0$\n",
    "\n",
    "\n",
    "Gradient Descent\n",
    "---\n",
    "\\begin{eqnarray*}\n",
    "\\theta_0 &\\leftarrow& \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^m \\left(h_{\\vec \\theta}(x^{(i)}) - y^{(i)} \\right)x_0^{(i)}\\\\\n",
    "\\theta_j &\\leftarrow& \\theta_j - \\alpha\\left[\\frac{1}{m}\\sum_{i=1}^m \\left(h_{\\vec \\theta}(x^{(i)}) - y^{(i)} \\right)x_0^{(i)} + \\frac{\\lambda}{m}\\theta_j \\right]\\\\\n",
    "&& = \\theta_j\\left(1-\\alpha \\frac{\\lambda}{m}\\right) - \\alpha\\frac{1}{m}\\sum_{i=1}^m \\left(h_{\\vec \\theta}(x^{(i)}) - y^{(i)} \\right)x_0^{(i)}\n",
    "\\end{eqnarray*}\n",
    "* $\\left(1-\\alpha \\frac{\\lambda}{m}\\right) < 1$, say 0.99. slowly makes $\\theta_j$ smaller and smaller\n",
    "\n",
    "Normal Equation with Regularization\n",
    "---\n",
    "\n",
    "Solve \n",
    "$$\n",
    "\\frac{\\partial}{\\partial\\theta_j} J(\\theta) = 0\n",
    "$$\n",
    "to get $\\theta = [X^TX + \\lambda \\text{ diag}(0, 1, 1, \\ldots, 1)]^{-1} X^T y$\n",
    "* regularization: if $m<n$ then $X^TX$ non-invertible, but with regularization the matrix is always invertible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 4\n",
    "===\n",
    "\n",
    "Neural Network Introduction\n",
    "---\n",
    "\n",
    "* motivation\n",
    "    * quadratic features has $O(n^2)$ terms if originally there are $n$ features; cubit features has $O(n^3)$ terms\n",
    "    * in many practical problems, like computer vision, $n$ is huge\n",
    "* popular in 80s and early 90s, then diminished in late 90s\n",
    "* the \"one learning algorithm\" hypothesis\n",
    "    * neural rewiring experiment; audio cortex can learn to see\n",
    "    * \"seeing with your tongue\", \"human sonar\", \"implanting a 3rd eye\", ...\n",
    "\n",
    "Neuron Model: Logistic Unit\n",
    "---\n",
    "\n",
    "* sigmoid (logistic) activation function, $x = (x_0, x_1, x_2, x_3)^T, \\theta = (\\theta_0, \\theta_1, \\theta_2, \\theta_3)^T$\n",
    "\n",
    "$$\n",
    "h_{\\vec\\theta}(x) = \\frac{1}{1+e^{-\\theta^T x}}\n",
    "$$\n",
    "\n",
    "* $x_0 = 1$, \"bias unit\"\n",
    "\n",
    "Neural Network\n",
    "---\n",
    "\n",
    "* forward propagation\n",
    "* input layer, hidden layers, output layer\n",
    "* $a^{(j)}$ (vector) activation of unit $i$ in layer $j$\n",
    "* $\\theta^{(j)}$ matrix of weights controling function mapping from layer $j$ to layer $j+1$\n",
    "* if layer $j$ has $s_j$ units than $\\theta^{(j)}$ has size $s_{j+1}\\times (s_j+1)$\n",
    "* example: \n",
    "    * input layer has 3 units\n",
    "    * hidden layer has 3 units\n",
    "    * output layer has 1 unit\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "a^{(2)} &=& g\\left(\\theta^{(1)}_{3\\times 4} x\\right) \\\\\n",
    "a^{(2)} &\\leftarrow & [1, a^{(2)}]\\qquad \\% \\text{ adding bias $a^{(2)}_0$} \\\\\n",
    "h_{\\vec\\theta} (x) &=& a^{(3)} = g\\left(\\theta^{(2)}_{1\\times 4} a^{(2)}\\right) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "* without hidden layer: equivalent to logistic regression\n",
    "* with hidden layer(s): output layer is a logistic regression with features learned from previous layers\n",
    "* a computer vision example: feature \"has a face or not\"\n",
    "* \"network architectures\": has more than one hidden layers\n",
    "\n",
    "True Value Tables\n",
    "---\n",
    "\n",
    "* how to construct network that computes $x_1$ XOR $x_2$? \n",
    "* example: AND\n",
    "$$\n",
    "h_{\\vec\\theta}(x) = g(-30 + 20 x_1 + 20 x_2)\n",
    "$$\n",
    "\n",
    "\n",
    "| $x_1$ $x_2$ | 　　　　　　|\n",
    "|---|-----------------------|\n",
    "| 0 0 | $g(-30)\\approx 0$ |\n",
    "| 0 1 | $g(-10)\\approx 0$ |\n",
    "| 1 0 | $g(-10)\\approx 0$ |\n",
    "| 1 1 | $g(10)\\approx 1$ |\n",
    "\n",
    "* coefficients determine how strong the pulse is \n",
    "* example: OR, $h_{\\vec\\theta}(x) = g(-10 + 20 x_1 + 20 x_2)$\n",
    "* example: NOT, $h_{\\vec\\theta}(x) = g(10 - 20 x_1)$, large negative feature coefficient\n",
    "\n",
    "| $x_1$ | $h_{\\vec\\theta}(x)$ |\n",
    "|---|---|\n",
    "| 0 | 　　1 |\n",
    "| 1 | 　　0 |\n",
    "\n",
    "* can construct some true value tables, e.g. (NOT $x_1$) AND (NOT $x_2$) $=g(-20x_1 - 20x_2 + 10)$\n",
    "* with multilayers, can construct any logic:\n",
    "    * example: XNOR (NOT XOR)\n",
    "    * $x_1$ XNOR $x_2$ = [$x_1$ AND $x_2$] OR [(NOT $x_1$) AND (NOT $x_2$)]$\n",
    "    * brackets are hidden layer neurons\n",
    "\n",
    "Multi-Class Classification\n",
    "---\n",
    "\n",
    "* outputs are standard basis vectors like $(1, 0, 0, 0)^T$ for the first class, $(0, 1, 0. 0)^T$ for the second, ..., instead of $y\\in\\{1, 2, 3, 4\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 5\n",
    "===\n",
    "\n",
    "Cost Function\n",
    "---\n",
    "\n",
    "* notation\n",
    "    * $L$: # layers in network\n",
    "    * $s_l$: # units in layer $l$\n",
    "* binary classification, $y = 0, 1$\n",
    "* multi-class classification ($K$ classes), $y = (1, 0, 0, 0)^T, (0, 1, 0, 0)^T, \\ldots$\n",
    "* logistic regression: \n",
    "\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{m} \\left[\\sum_{i=1}^m y^{(i)}\\log(h_{\\theta}(x^{(i)})) + (1-y^{(i)})\\log(1 - h_{\\theta}(x^{(i)}))\\right] + \\frac{\\lambda}{2m}\\sum_{j=1}^n \\theta^2_j\n",
    "$$\n",
    "\n",
    "\n",
    "* neural network:\n",
    "\n",
    "\n",
    "$$\n",
    "J(\\theta) = -\\frac{1}{m} \\left[\\sum_{i=1}^m \\sum_{k=1}^K y_k^{(i)}\\log(h_{\\theta}(x^{(i)})_k) + (1-y^{(i)}_k)\\log(1 - h_{\\theta}(x^{(i)})_k)\\right] + \\frac{\\lambda}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_{l}}\\sum_{j=1}^{s_{l+1}} (\\theta_{ji}^{(l)})^2\n",
    "$$\n",
    "\n",
    "Backpropagation\n",
    "---\n",
    "\n",
    "* forward propagation (4 layers): \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "x &\\leftarrow& [1, x] \\qquad \\% \\text{ adding bias } \\\\\n",
    "a^{(2)} &=& g\\left(\\theta^{(1)} x\\right) \\\\\n",
    "a^{(2)} &\\leftarrow & [1, a^{(2)}]\\qquad \\% \\text{ adding bias $a^{(2)}_0$} \\\\\n",
    "a^{(3)} &=& g\\left(\\theta^{(2)} a^{(2)}\\right) \\\\\n",
    "a^{(3)} &\\leftarrow & [1, a^{(3)}]\\qquad \\% \\text{ adding bias $a^{(3)}_0$} \\\\\n",
    "h_{\\vec\\theta} (x) = a^{(4)} &=& g\\left(\\theta^{(1)} a^{(3)}\\right) \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* backward propagation: $\\delta_j^{(l)}$ is the error of activation $a_j^{(l)}$ at node $j$ in layer $l$\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\delta^{(4)} &=& a^{(4)} - y \\\\\n",
    "\\delta^{(3)} &=& (\\theta^{(3)})^T \\delta^{(4)}.* g^\\prime(\\theta^{(2)} a^{(2)}) \\\\\n",
    "\\delta^{(2)} &=& (\\theta^{(2)})^T \\delta^{(3)}.* g^\\prime(\\theta^{(1)} [1, x]) \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "* no $\\delta^{(1)}$ because first layer is $x$, no error\n",
    "* if $\\lambda = 0$ (no regularization), then the derivative of $J$ is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta_{ij}^{(l)}} J(\\theta) = a^{(l)}_j\\delta_i^{(l+1)}\n",
    "$$\n",
    "\n",
    "* it can be shown that $g^\\prime(\\theta^{(2)} a^{(2)}) = a^{(3)}.*(1-a^{(3)})$\n",
    "* algorighm: \n",
    "    * Training set $\\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(m)}, y^{(m)})\\}$\n",
    "    * Set $\\Delta_{ij}^{(l)} = 0$ for all $l, i, j$\n",
    "    * For $i=1$ to $m$\n",
    "        * Set $a^{(1)} = x^{(i)}$\n",
    "        * Perform forward propagation to compute $a^{(l)}$ for $l = 2, 3, \\ldots, L$\n",
    "        * Using $y^{(i)}$, compute $\\delta^{(L)} = a^{(L)} - y^{(i)}$\n",
    "        * Compute $\\delta^{(L-1)}, \\delta^{(L-2)}, \\ldots, \\delta^{(2)}$\n",
    "        * $\\Delta_{ij}^{(l)} = \\Delta_{ij}^{(l)} + a_j^{(l)}\\delta_{i}^{(l+1)}$\n",
    "    * $D_{ij}^{(l)} = \\frac1m\\Delta_{ij}^{(l)} + \\lambda \\theta_{ij}^{(l)}$ if $j\\neq 0$\n",
    "    * $D_{ij}^{(l)} = \\frac1m\\Delta_{ij}^{(l)} \\qquad$ if $j = 0$\n",
    "    * $\\frac{\\partial}{\\partial \\theta_{ij}^{(l)}} J(\\theta) = D_{ij}^{(l)}$\n",
    "\n",
    "Intuition of Backpropagation\n",
    "---\n",
    "\n",
    "* let $z^{(l)} = \\theta^{(l-1)}a^{(l-1)}$ (sending $z^{(l)}$ to $g$ will get activation $a^{(l)}$). formally, \n",
    "\n",
    "$$\n",
    "    \\delta_j^{(l)} = \\frac{\\partial}{\\partial z_j^{(l)}} \\text{cost}(i) = \\frac{\\partial}{\\partial z_j^{(l)}} \\left[y^{(i)}\\log h_{\\theta}(x^{(i)}) + (1-y^{(i)})\\log h_{\\theta}(x^{(i)})\\right]\n",
    "$$\n",
    "\n",
    "* how much the cost would change if the intermediate value $z$ changes by a small amount\n",
    "\n",
    "Unrolling Parameters\n",
    "---\n",
    "\n",
    "* $\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, D^{(1)}, D^{(2)}, D^{(3)}, \\ldots$: matrices\n",
    "* unroll as a giant (column) vector in octave, to make use of the built-in optimization function: \n",
    "\n",
    "```\n",
    "thetaVector = [Theta1(:); Theta2(:); Theta3(:)]\n",
    "deltaVector = [D1(:); D2(:); D3(:)]\n",
    "```\n",
    "\n",
    "* put it back as matrices: \n",
    "\n",
    "```\n",
    "Theta1 = reshape(thetaVector(1:110), 10, 11)\n",
    "Theta2 = reshape(thetaVector(111:220), 10, 11)\n",
    "Theta3 = reshape(thetaVector(221:231), 10, 11)\n",
    "```\n",
    "\n",
    "* ```thetaVector(111:220)``` takes the 111th - 220th elements of ```thetaVector```\n",
    "\n",
    "Gradient Checking\n",
    "---\n",
    "\n",
    "* backprop is very complicated; the implementation can be buggy \n",
    "* always compare the derivatives obtained by backpropagation with finite difference\n",
    "\n",
    "$$\n",
    "\\frac{J(\\theta+\\epsilon) - J(\\theta-\\epsilon)}{2\\epsilon}, \\qquad \\epsilon = 10^{-4}\n",
    "$$ \n",
    "\n",
    "* $\\theta$'s are all vectors obtained by unrolling matrices; compute the partial derivative element by element and put them all together to get the gradient\n",
    "\n",
    "```\n",
    "for i = 1:n, \n",
    "    thetaPlus = theta;\n",
    "    thetaPlus(i) = thetaPlus(i) + EPSILON;\n",
    "    thetaMinus = theta;\n",
    "    thetaMinus(i) = thetaMinus(i) - EPSILON;\n",
    "    gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*EPSILON);\n",
    "end;\n",
    "```\n",
    "\n",
    "* check that ```gradApprox``` and ```DVec``` are approximately the same\n",
    "* implementation: \n",
    "    * implement backprop to compute ```Dvec```\n",
    "    * implement numerical gradient check to compute ```gradApprox```; make sure they give similar values\n",
    "    * turn off gradient checking; use backprop code for learning\n",
    "* if forget to turn of gradient checking the training will be very slow\n",
    "\n",
    "Random Initialization \n",
    "---\n",
    "\n",
    "* \"problem of symmetry breaking\": if set $\\theta_{ji}^{(l)}$ to the same value (say 0) for all $i, j, l$, then all activations in the same layer will be the same, event after many iterations\n",
    "* initialize each $\\theta_{ij}^{(l)}$ to a random value in $[-\\epsilon, \\epsilon]$\n",
    "\n",
    "```\n",
    "Theta1 = rand(10, 11)*(2*INIT_EPSILON) - INIT_EPSILON\n",
    "Theta1 = rand(1, 11)*(2*INIT_EPSILON) - INIT_EPSILON\n",
    "```\n",
    "\n",
    "* ```rand(10, 11)``` gives 10 by 11 random matrix with $U(0, 1)$ distributed elements\n",
    "\n",
    "Putting it Together\n",
    "---\n",
    "\n",
    "* reasonable default: 1 hidden layer, or if >1 hidden layers, have same number of hidden units in every layer (usually the more the better, but also more expensive to train the model)\n",
    "* training a neural network: \n",
    "    1. randomly initialize weights\n",
    "    * implement forward propagation go get $h_{\\theta}(x^{(i)})$ for any $x^{(i)}$\n",
    "    * implement code to compute cost function $J$\n",
    "    * implement backprop to compute partial derivatives of $J$\n",
    "        * for i = 1:m\n",
    "            * perform forward propagation and backprop using example $(x^{(i)}, y^{(i)})$ (get activations and deltas)\n",
    "        * there are ways other than for loop to implement backprp, but for the first time just implement the simple for loop version\n",
    "    * use gradient checking to make sure backprop is implemented correctly; then disable the gradient checking code\n",
    "    * use gradient descent or advanced optimization method with backprop to minimize $J$\n",
    "        * $J$ is non-convex, so in theory there is no guarantee of a global minimum, but in practice iterative algorithms work well\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
